
# Big Data Examples

This repository contains several examples of big data processing using different frameworks. Each example demonstrates how to process and analyze data using Python libraries and tools such as Dask, MapReduce, MRJob, and PySpark.

## Directory Structure

- `dask/` - Dask-based examples
- `map_reduce/` - MapReduce examples (pure Python)
- `mrjob/` - MapReduce examples using MRJob
- `pyspark/` - PySpark examples
- `data/` - Input datasets
- `output/` - Output files generated by the examples

## Prerequisites

- Python 3.7+
- [Poetry](https://python-poetry.org/) for dependency management
- Recommended: Create and activate a virtual environment

Install dependencies:

```zsh
poetry install
```

## Running the Examples

### Dask Example

```zsh
poetry run python dask/avg_temperature.py
```

### MapReduce (Pure Python)

```zsh
poetry run python map_reduce/avg_temperature.py
poetry run python map_reduce/word_count.py
```

### MRJob Example

```zsh
poetry run python mrjob/avg_temperature.py
```

### PySpark Example

Make sure you have Java and Spark installed. Then run:

```zsh
poetry run python pyspark/avg_temperature.py
```

## Input Data

All examples use files from the `data/` directory:
- `city_temperature.csv` for temperature analysis
- `the_adventures_of_sherlock_holmes.txt` for word count

## Output

Results are saved in the `output/` directory.
